---
title: "Estimating additive variance explained by risk mutations"
author: "Kevin Thornton"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Estimating additive variance explained by risk mutations}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

# Introduction

This vignette gives an overview on how to estimate the fraction of additive genetic variation due to risk mutations
at frequency $\leq p$.

Let's assume we have the follwing:

1. index.txt is the index file output by a simulation
2. pop.bin.gz is the file containing the simulated replicates

We want to use R's aov() function to fit an additive model to all markers.  The response variable will be $G$, the
genetic component of phenotype for each diploid.  Each diploid's genotype will be coded as 0, 1, or 2 copies of a risk mutation 
into a matrix, $M$, whose dimensions are $N$ rows (the population size) and $k$ columns, which is the number of risk mutations (after removing 
duplicate columns).

Essentially, what is going on here is:

~~~{r}
summary(aov(G ~ ., data=as.data.frame(M)))
~~~

The relevant functions are:

* diseaseSims::getRiskVariantMatrix
* diseaseSims::vpv1aov

## Working example

```{r,fig.width=5,fig.height=5}
library(diseaseSims)
library(dplyr)
idx=read.table(system.file("extdata", "index.txt", package = "diseaseSims"))
popfile=system.file("extdata", "pop.bin.gz", package = "diseaseSims")
OFFSET=0
for(i in 1:nrow(idx))
    {
      ##Get the risk variant matrix for the population
      XX=getRiskVariantMatrix(popfile,OFFSET,model="additive")
      XX.aov = vpv1aov(XX)
      if( i == 1 )
      {
	plot(XX.aov$p,XX.aov$rsq,
		xlab="Mutation frequency",
		ylab="Variance explained",
		xlim=c(0,0.1),type="l",
		main="3 replicates, additive model")
      }
      else
      {
	lines(XX.aov$p,XX.aov$adj.rsq,col=i)
      }
      OFFSET=OFFSET+idx$V4[i]
    }
```

## Some details

Currently, we support the following three methods for fitting the linear models:

* lm, from R's base package
* slm, from [SparseM](http://cran.r-project.org/web/packages/SparseM/index.html)
* biglm, from [biglm](http://cran.r-project.org/web/packages/biglm/index.html)

These method names may be supplied as arguments to vpv1aov.  The function will override your supplied method name if the following condition holds:

~~~{r}
prod( as.numeric(dim(m)) ) >= .Machine$integer.max
~~~

If that condition holds, the method will be changed to "biglm".  If the "biglm" package namespace cannot be found, execution will stop at this point 
with an error.

Our recommendations for choosing a method are:

* use lm for small data sets ( $N \approx O(10^4)$ and 100s of risk mutations )
* use slm for large data sets, where the data frames contain $O(10^9)$ elements
* Let the code decide if and when biglm should be used.  In this case, a warning will be emitted informing you that the code will use biglm instead.

In all honesty, we have not checked which of slm or biglm is the faster method.  

The reason why you cannot use slm with data frames larger than the maximum integer size is the following:

1. In R, the maximum length of a matrix (e.g, prod(dim(m))) is .Machine$integer.max (because matrices in R are stored as linear arrays with dimenion attribues)
2. In R, the maximum size of a data.frame is .Machine$integer.max elements ("columns"), each of which may be .Machine$integer.max ("rows") long.
3. Internally, slm makes a call to as.matrix.  If your data.frame is "too big", execution will stop.

## Warning: big RAM alert!

These analyses can be very RAM-intensive.  We have worked with the following diploid population sizes:

* $N = 20^4$
* $N = 10^6$

For our work, the larger $N$ corresponds to the end of an exponential growth model.  Processing the output of the smaller 
population size required a trivial amount of RAM ( $\leq 400$ Gb).  However, the peak RAM use for the growth simulations was typically
$\approx 70$ Gb, and the initial reading in of the data alon required about 8Gb.  It is therefore possible that processing such large populations
will not be possible for all users.  In principle, this issue can be solved via a combination of the [bigmemory](http://cran.r-project.org/web/packages/bigmemory/index.html)
and [biglm](http://cran.r-project.org/web/packages/biglm/index.html) packages, but we have not looked into that.